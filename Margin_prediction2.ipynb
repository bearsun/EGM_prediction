{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one lightGBM model for EGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "data = pd.read_csv('df_egm.csv', parse_dates=['order_date'])\n",
    "# feature with no variance / duplicated feature\n",
    "data.drop(['store_id', 'is_liquidation', 'is_cancelled'], axis = 1, inplace = True)\n",
    "# duplicated\n",
    "data = data[~data['id'].duplicated()]\n",
    "# drop cancelled\n",
    "data = data[data['quantity_cancelled'] == 0]\n",
    "\n",
    "data['date'] = data['order_date'].dt.date\n",
    "data['cost'] = data['cost_product'] + data['cost_shipping'] + data['cost_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_egm = data[['id', 'date','revenue_net', 'cost']].copy()\n",
    "ds_egm['egm'] = 1 - ds_egm['cost']/ds_egm['revenue_net']\n",
    "# exluding revenue_net = 0: can't calculate EGM\n",
    "ds_egm.loc[ds_egm['revenue_net'] == 0, 'egm'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mask = ds_egm['egm'].abs()<=3\n",
    "out_mask = ds_egm['egm'].abs()>3\n",
    "nan_mask = ds_egm['egm'].isnull()\n",
    "ntotal = ds_egm.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_used:\n",
      "0.9495986646016417\n",
      "\n",
      "total_used (no NaN):\n",
      "0.9892794970722577\n"
     ]
    }
   ],
   "source": [
    "print('total_used:')\n",
    "print(in_mask.sum()/ntotal)\n",
    "print('\\ntotal_used (no NaN):')\n",
    "print(in_mask.sum()/(ntotal-nan_mask.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[in_mask]\n",
    "data['egm'] = 1 - data['cost']/data['revenue_net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_name to predict\n",
    "name = 'egm'\n",
    "# continuous features\n",
    "conts = ['date', 'sale_price', 'wholesale_price', 'revenue_product', 'revenue_shipping', 'shipping_pred', 'quantity_initial', 'egm']\n",
    "# categorical features\n",
    "cats = ['shipping_speed_id', 'supplier_id', 'category_id', 'class_id', 'carrier_id', 'manufacturer_id', 'is_b2b', 'is_giftcard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data, conts, cats, y_name):\n",
    "    # continuous features\n",
    "    ds = data[conts].copy()\n",
    "    # categorical features: code to 0 - (n-1)\n",
    "    for cat in cats:\n",
    "        ds[cat] = LabelEncoder().fit_transform(data[cat].copy())\n",
    "        ds.loc[data[cat].isnull(), cat] = np.nan\n",
    "    \n",
    "    # time\n",
    "    ds['month'] = data['order_date'].dt.month.copy() - 1\n",
    "    ds['dom'] = data['order_date'].dt.day.copy() - 1\n",
    "    ds['dow'] = data['order_date'].dt.dayofweek.copy()\n",
    "    cats.extend(['month', 'dow'])\n",
    "    \n",
    "    # train/val/test split\n",
    "    ds_train = ds[ds['date'] < date(2018, 6, 17)].copy()\n",
    "    ds_val = ds[(ds['date'] >= date(2018, 6, 17)) & (ds['date'] <= date(2018, 7, 16))].copy()\n",
    "    ds_test = ds[ds['date'] > date(2018, 7, 16)].copy()\n",
    "    ds_train.drop('date', axis = 1, inplace = True)\n",
    "    ds_val.drop('date', axis = 1, inplace = True)\n",
    "    ds_test.drop('date', axis = 1, inplace = True)\n",
    "    \n",
    "    # X/y split\n",
    "    X_train = ds_train.drop(y_name, axis = 1)\n",
    "    y_train = ds_train[y_name]\n",
    "    \n",
    "    X_val = ds_val.drop(y_name, axis = 1)\n",
    "    y_val = ds_val[y_name]\n",
    "    \n",
    "    X_test = ds_test.drop(y_name, axis = 1)\n",
    "    y_test = ds_test[y_name]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, cats = prep_data(data, conts, cats, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "feat = X_train.columns.tolist()\n",
    "params = {\n",
    "    'num_leaves': 21,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 600,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'metric': 'l1',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 3000\n",
    "dtrain = lgb.Dataset(X_train, label = y_train, categorical_feature=cats)\n",
    "dval = lgb.Dataset(X_val, label = y_val, reference=dtrain, categorical_feature=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bearsun/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1184: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/bearsun/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l1: 0.133182\tvalid_1's l1: 0.141888\n",
      "[100]\ttraining's l1: 0.129143\tvalid_1's l1: 0.138866\n",
      "[150]\ttraining's l1: 0.126753\tvalid_1's l1: 0.136683\n",
      "[200]\ttraining's l1: 0.125587\tvalid_1's l1: 0.135562\n",
      "[250]\ttraining's l1: 0.124873\tvalid_1's l1: 0.13501\n",
      "[300]\ttraining's l1: 0.124215\tvalid_1's l1: 0.134464\n",
      "[350]\ttraining's l1: 0.123876\tvalid_1's l1: 0.134116\n",
      "[400]\ttraining's l1: 0.123418\tvalid_1's l1: 0.133595\n",
      "[450]\ttraining's l1: 0.123129\tvalid_1's l1: 0.13342\n",
      "[500]\ttraining's l1: 0.122894\tvalid_1's l1: 0.133203\n",
      "[550]\ttraining's l1: 0.122628\tvalid_1's l1: 0.132859\n",
      "[600]\ttraining's l1: 0.122438\tvalid_1's l1: 0.132684\n",
      "[650]\ttraining's l1: 0.122384\tvalid_1's l1: 0.132622\n",
      "[700]\ttraining's l1: 0.122264\tvalid_1's l1: 0.132492\n",
      "[750]\ttraining's l1: 0.122091\tvalid_1's l1: 0.132286\n",
      "[800]\ttraining's l1: 0.121945\tvalid_1's l1: 0.132161\n",
      "[850]\ttraining's l1: 0.121822\tvalid_1's l1: 0.13204\n",
      "[900]\ttraining's l1: 0.121636\tvalid_1's l1: 0.131883\n",
      "[950]\ttraining's l1: 0.121568\tvalid_1's l1: 0.131821\n",
      "Early stopping, best iteration is:\n",
      "[944]\ttraining's l1: 0.121548\tvalid_1's l1: 0.131758\n"
     ]
    }
   ],
   "source": [
    "# train revenue model\n",
    "bst = lgb.train(params, dtrain, num_boost_round=MAX_ROUNDS, valid_sets=[dtrain, dval],\n",
    "                    early_stopping_rounds=50, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_importance:\n",
      "supplier_id: 35365.82\n",
      "class_id: 29058.08\n",
      "manufacturer_id: 21221.39\n",
      "revenue_product: 11370.99\n",
      "wholesale_price: 10183.87\n",
      "sale_price: 4653.54\n",
      "month: 2226.20\n",
      "revenue_shipping: 1092.34\n",
      "is_b2b: 785.06\n",
      "shipping_speed_id: 577.57\n",
      "dow: 388.13\n",
      "shipping_pred: 382.12\n",
      "category_id: 376.22\n",
      "quantity_initial: 322.58\n",
      "dom: 121.27\n",
      "carrier_id: 56.72\n",
      "is_giftcard: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('Feature_importance:')\n",
    "print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12154786426500057"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = bst.predict(X_train)\n",
    "mean_absolute_error(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13487910493701635"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = bst.predict(X_test)\n",
    "mean_absolute_error(y_test, test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
